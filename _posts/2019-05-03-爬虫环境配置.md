---
layout: post
title: "爬虫环境配置"
date: 2019-05-03
categories: 网络爬虫 Python
tags: 网络爬虫 Python
author: Quan Zhang
---

## linux安装python

```
sudo yum install -y https://centos7.iuscommunity.org/ius-release.rpm
sudo yum update
sudo yum install -y python35u python35u-libs python35u-devel python35u-pip
```
测试安装
```
python3
pip3 -V
```

## 请求库安装

爬虫可分为如下步骤：

- 抓取页面
- 分析页面
- 存储数据

用到的第三方库有：request、selenium、aiohttp

### request

```
https://pypi.org/project/request/

打开anaconda prompt
pip3 install request
```
调用模块

```
>>> import request

>>> request.REQUEST
{...}
```

### selenium

```
pip3 install selenium
```

### 谷歌浏览器驱动

安装了selenium，这只是个自动化测试工具，需要浏览器来配合使用，接下来介绍Chrome浏览器及其驱动的配置。

- 查看谷歌浏览器的版本号
- 下载相应的ChromeDriver
- 将ChromeDriver放入python的scripts文件夹下
- 测试环境，会弹开一个空白网页

```
from selenium import webdriver
browser = webdriver.Chrome()
```

### 无界面浏览器

Chrome在爬取网页的过程中浏览器可能一直动来动去，可以安装一个无界面浏览器PhantomJS.

PhantomJS是一个无界面的、可脚本编程的webKit浏览器引擎，它原生支持多种web标准：DOM操作，CSS选择器、JSON、Canvas以及SVG.

【也可用headless】

selenium支持PhantomJS，这样在运行的时候就不会再弹出一个浏览器了。而且PhantomJS的运行效率也很高，还支持各种参数匹配，使用方便。

- 下载解压
- 将bin目录里的exe放入anaconda（python）的scripts目录下
- 测试，打印输出https://www.baidu.com

```
from selenium import webdriver
browser = webdriver.PhantomJS()
browser.get('https://www.baidu.com')
print(browser.current_url)
```

### aiohttp

request库是一个阻塞式库，程序会一直等待服务器响应。

aiohttp是一个提供异步web服务的库，从python3.5版本开始，python加入了async/await关键字，使得回调的写法更加直观和人性化。aiohttp的异步操作借助于async、await关键字。

```
pip3 install aiohttp
```
字符编码检测库cchardet和dns加速解析库
```
pip3 install cchardet aiodns
```
测试库：
```
import aiohttp
```

## 解析库

抓取网页后，下一步就是从网页中提取信息。提取信息的方式有多种多样，可以使用正则表达式提取，比较繁琐，还可以用解析库：lxml、Beautiful Soup、pyquery等。此外，还提供了非常强大的解析方法，如XPath解析和CSS选择器解析等，利用他们，我们可以高效便捷地从网页提取信息。

### lxml

支持HTML和xml解析，支持xpath解析，效率高。

```
pip3 install lxml
```
验证：
```
import lxml
```

### Beautiful Soup

html和xml解析库。
```
pip3 install beautifulsoup4
```
验证，输出Hello，注意安装名和包名的变化。
```
from bs4 import BeautifulSoup
soup = BeautifulSoup('<p>Hello</p>','lxml')
print(soup.p.string)
```

### pyquery

提供jQuery类似的语法来解析HTML文档，支持css选择器，使用方便。
```
pip3 install pyquery
```
验证
```
import pyquery
```

### tesserocr

利用OCR识别图形验证码，安装前需要安装核心tesseract。

- 下载不带dev的3.05.01版本
- 勾选additional language data来安装语言包
- 再pip安装ocr【下载压缩包本地安装】
```
pip3 install tesserocr pillow
```
#### 测试识别验证码

```
import tesserocr
from PIL import Image
image = Image.open('C://image.png')
print(tesserocr.image_to_text(image))
#运行结果输出字符...
#出错的话，把tessdata拷贝到报错目录
```

## 数据库

- 关系数据库：SQQLite,MySQL,Oracle
- 非关系数据库：MongoDB、Redis，存储形式是键值，存储形式灵活。

这里用到的数据库：MySQL和MongoDB、Redis。

### 安装mysql

### MongoDB

MongoDB是由C++语言编写的非关系数据库，是一个基于分布式文件存储的开源数据库系统，其内容存储形式类似JSON对象，字段值可以包含其他文档，数组及文档数组。

- 安装软件
- 运行服务

```
mongod --dpath "C:\Program Files\MongoDB\Server\4.0\data\db"
```

- 保持服务运行

意思是绑定IP为0.0.0.0，指定日志路径、数据库路径和端口，指定服务名称。在服务中可以看见MongoDB服务已经开启，可以设置为自动启动。
```
mongod --bind_ip 0.0.0.0 --logpath "C:\Program Files\MongoDB\Server\4.0\logs\mongod.log" --logappend --dbpath "C:\Program Files\MongoDB\Server\4.0\data\db" --port 27017 --serviceName "MongoDB" --serviceDisplayName "MongoDB" --install
```
- mongo命令进行交互
- 可视化工具：RoboMongo

### Redis

Redis是一个基于内存的高效的非关系型数据库。

- 安装Redis，安装完成即可在服务上查看是否启动。
- 可视化工具Redis Desktop Manager

## 存储库

还需要安装一些Python存储库，MySQL需要安装PyMySQL，MongoDB需要安装PyMongo。

- mysql
```
pip3 install pymysql
```
```
import pymysql
pymysql.VERSION
```
- mongo
```
pip3 install pymongo
```
```
import pymongo
pymongo.version
```
- redis
```
pip3 install redis
```
```
import redis
redis.VERSION
```
- redisDump是一个用于Redis数据导入导出的工具，基于Ruby实现

1. 安装ruby
2. 安装redisDump

```
gem install redis-dump
```
验证
```
redis-dump
redis-load
```

## web库

需要web服务提供api接口，只需要请求接口即可获取新的代理。

### flask

一个轻量级的web服务程序，主要做一些api服务。

```
pip3 install flask
```
测试
```
from flask import Flask
app = Flask(__name__)
@app.route("/")
def hello():
    return "Hello world"
if __name__ == "__main__":
    app.run()
```
后面会利用flask+redis维护动态代理池和cookies池。

### Tornado

支持异步的web框架，通过使用非阻塞I/O流，它可以支撑很多开放连接，效率高。

```
pip3 install tornado
```
验证
```
import tornado.ioloop
import tornado.web 
class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write("Hello, world")
application = tornado.web.Application([(r"/index", MainHandler),])
if __name__ == "__main__":
    application.listen(8888)
    tornado.ioloop.IOLoop.instance().start()
#浏览器访问http://127.0.0.1:8888/index，显示hello,world
```
后面，会利用tornado+redis搭建一个ADSL拨号代理池。

## App爬取相关库的安装

App可通过抓包爬取数据，抓包工具有Charles/mitmproxy/mitmdump。一些简单的接口可以通过Charles或mitmproxy分析，找出规律，然后直接用程序模拟来抓取。但是如果遇到复杂的接口，就需要用mitmdump对接python来对抓取到的请求和响应进行实时处理和保存。另外，既然要做规模采集，就需要自动化App的操作而不是人工采集，所以这里还需要一个Appium工具，模拟App点击、下来操作。

